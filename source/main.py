import asyncio
import aiohttp
import re
import base64
import json
import os
import ipaddress
import math
import time
from collections import defaultdict
from urllib.parse import urlparse
from typing import List, Tuple, Optional
from datetime import datetime

# -------------------- –ù–ê–°–¢–†–û–ô–ö–ò --------------------
PING_TIMEOUT = 3.0
MAX_PING_MS = 1000  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π –ø–∏–Ω–≥
CONCURRENT_PINGS = 30
SERVERS_PER_SOURCE = 200  # –ü–æ 200 –ª—É—á—à–∏—Ö —Å –∫–∞–∂–¥–æ–≥–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞

ALLOWED_PROTOCOLS = ['vless', 'vmess', 'ss']

# -------------------- –ò–°–¢–û–ß–ù–ò–ö–ò --------------------
URLS = [
    "https://github.com/sakha1370/OpenRay/raw/refs/heads/main/output/all_valid_proxies.txt",  # 1
    "https://raw.githubusercontent.com/sevcator/5ubscrpt10n/main/protocols/vl.txt",  # 2
    "https://raw.githubusercontent.com/yitong2333/proxy-minging/refs/heads/main/v2ray.txt",  # 3
    "https://raw.githubusercontent.com/acymz/AutoVPN/refs/heads/main/data/V2.txt",  # 4
    "https://raw.githubusercontent.com/miladtahanian/V2RayCFGDumper/refs/heads/main/sub.txt",  # 5
    "https://raw.githubusercontent.com/roosterkid/openproxylist/main/V2RAY_RAW.txt",  # 6
    "https://github.com/Epodonios/v2ray-configs/raw/main/Splitted-By-Protocol/trojan.txt",  # 7
    "https://raw.githubusercontent.com/CidVpn/cid-vpn-config/refs/heads/main/general.txt",  # 8
    "https://raw.githubusercontent.com/mohamadfg-dev/telegram-v2ray-configs-collector/refs/heads/main/category/vless.txt",
    # 9
    "https://raw.githubusercontent.com/mheidari98/.proxy/refs/heads/main/vless",  # 10
    "https://raw.githubusercontent.com/youfoundamin/V2rayCollector/main/mixed_iran.txt",  # 11
    "https://github.com/expressalaki/ExpressVPN/blob/main/configs3.txt",  # 12
    "https://raw.githubusercontent.com/MahsaNetConfigTopic/config/refs/heads/main/xray_final.txt",  # 13
    "https://github.com/LalatinaHub/Mineral/raw/refs/heads/master/result/nodes",  # 14
    "https://github.com/miladtahanian/Config-Collector/raw/refs/heads/main/vless_iran.txt",  # 15
    "https://raw.githubusercontent.com/Pawdroid/Free-servers/refs/heads/main/sub",  # 16
    "https://github.com/MhdiTaheri/V2rayCollector_Py/raw/refs/heads/main/sub/Mix/mix.txt",  # 17
    "https://raw.githubusercontent.com/free18/v2ray/refs/heads/main/v.txt",  # 18
    "https://github.com/MhdiTaheri/V2rayCollector/raw/refs/heads/main/sub/mix",  # 19
    "https://github.com/Argh94/Proxy-List/raw/refs/heads/main/All_Config.txt",  # 20
    "https://raw.githubusercontent.com/shabane/kamaji/master/hub/merged.txt",  # 21
    "https://raw.githubusercontent.com/wuqb2i4f/xray-config-toolkit/main/output/base64/mix-uri",  # 22
    "https://raw.githubusercontent.com/Delta-Kronecker/V2ray-Config/refs/heads/main/config/protocols/vless.txt",  # 23
    "https://raw.githubusercontent.com/STR97/STRUGOV/refs/heads/main/STR.BYPASS#STR.BYPASS%F0%9F%91%BE",  # 24
    "https://raw.githubusercontent.com/V2RayRoot/V2RayConfig/refs/heads/main/Config/vless.txt",  # 25
]


# -------------------- –õ–û–ì–ò–†–û–í–ê–ù–ò–ï --------------------
def log(message: str):
    """–î–æ–±–∞–≤–ª—è–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ –ª–æ–≥"""
    timestamp = datetime.now().strftime("%H:%M:%S")
    print(f"[{timestamp}] {message}")


# -------------------- HTTP –ö–õ–ò–ï–ù–¢ --------------------
class HTTPFetcher:
    def __init__(self):
        self.headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
        }
        self.session = None

    async def __aenter__(self):
        self.session = aiohttp.ClientSession(
            headers=self.headers,
            timeout=aiohttp.ClientTimeout(total=30)
        )
        return self

    async def __aexit__(self, *args):
        if self.session:
            await self.session.close()

    async def fetch(self, url: str) -> Optional[str]:
        """–ó–∞–≥—Ä—É–∑–∫–∞ —Å retry"""
        for attempt in range(1, 4):
            try:
                async with self.session.get(url, timeout=20, ssl=False) as resp:
                    if resp.status == 200:
                        return await resp.text()
                    else:
                        if attempt < 3:
                            await asyncio.sleep(1)
            except Exception as e:
                if attempt < 3:
                    await asyncio.sleep(1)
        return None


# -------------------- –ü–ê–†–°–ï–† –ö–û–ù–§–ò–ì–û–í --------------------
class ConfigParser:
    INSECURE_PATTERN = re.compile(
        r'(?:[?&;]|3%[Bb])(allowinsecure|allow_insecure|insecure)=(?:1|true|yes)(?:[&;#]|$|(?=\s|$))',
        re.IGNORECASE
    )

    @staticmethod
    def decode_base64(text: str) -> str:
        try:
            text = re.sub(r'\s+', '', text)
            missing = len(text) % 4
            if missing:
                text += '=' * (4 - missing)
            return base64.b64decode(text).decode('utf-8', errors='ignore')
        except:
            return ""

    @staticmethod
    def extract_keys(text: str) -> List[str]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –≤—Å–µ –∫–æ–Ω—Ñ–∏–≥–∏ –∏–∑ —Ç–µ–∫—Å—Ç–∞"""
        if not text:
            return []
        patterns = [
            r'(vmess://[a-zA-Z0-9+/=]+)',
            r'(vless://[a-f0-9-]+@[a-zA-Z0-9.-]+:\d+)',
            r'(ss://[a-zA-Z0-9+/=]+[@#])',
            r'(trojan://[a-zA-Z0-9-]+@[a-zA-Z0-9.-]+:\d+)',
            r'(ss://[a-zA-Z0-9+/=]+)',
        ]
        found = []
        for p in patterns:
            found.extend(re.findall(p, text, re.IGNORECASE))
        return list(set(found))

    @staticmethod
    def extract_host_port(config: str) -> Tuple[Optional[str], Optional[int]]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ö–æ—Å—Ç –∏ –ø–æ—Ä—Ç –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞"""
        try:
            if config.startswith('vmess://'):
                try:
                    data = config[8:]
                    decoded = ConfigParser.decode_base64(data)
                    if decoded and decoded.startswith('{'):
                        j = json.loads(decoded)
                        return j.get('add'), int(j.get('port', 0))
                except:
                    pass

            parsed = urlparse(config)
            if parsed.hostname and parsed.port:
                return parsed.hostname, parsed.port

            parts = config.split('://')[1].split('@')
            addr = parts[-1].split('/')[0].split('?')[0]
            if ':' in addr:
                h, p = addr.split(':')
                return h, int(p)
        except:
            pass
        return None, None

    @staticmethod
    def filter_insecure(data: str) -> Tuple[str, int]:
        """–§–∏–ª—å—Ç—Ä—É–µ—Ç –Ω–µ–±–µ–∑–æ–ø–∞—Å–Ω—ã–µ –∫–æ–Ω—Ñ–∏–≥–∏"""
        lines = data.splitlines()
        result = []
        filtered = 0

        for line in lines:
            if ConfigParser.INSECURE_PATTERN.search(line):
                filtered += 1
                continue
            result.append(line)

        return "\n".join(result), filtered


# -------------------- –ü–†–û–í–ï–†–ö–ê –ü–ò–ù–ì–ê --------------------
async def check_server_ping(config: str, semaphore: asyncio.Semaphore) -> Tuple[Optional[str], Optional[float]]:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø–∏–Ω–≥ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç (–∫–æ–Ω—Ñ–∏–≥, –ø–∏–Ω–≥) –µ—Å–ª–∏ –ø–∏–Ω–≥ <= MAX_PING_MS"""
    host, port = ConfigParser.extract_host_port(config)
    if not host or not port:
        return None, None

    async with semaphore:
        try:
            start = time.time()

            # DNS check
            try:
                ipaddress.ip_address(host)
            except ValueError:
                await asyncio.get_event_loop().getaddrinfo(host, port)

            # TCP connect
            conn = asyncio.open_connection(host, port)
            _, writer = await asyncio.wait_for(conn, timeout=PING_TIMEOUT)

            elapsed = (time.time() - start) * 1000
            writer.close()
            await writer.wait_closed()

            if elapsed <= MAX_PING_MS:
                return config, elapsed
            else:
                return None, elapsed  # –°–ª–∏—à–∫–æ–º –º–µ–¥–ª–µ–Ω–Ω—ã–π

        except:
            return None, None


# -------------------- –û–ë–†–ê–ë–û–¢–ö–ê –û–î–ù–û–ì–û –ò–°–¢–û–ß–ù–ò–ö–ê --------------------
async def process_source(idx: int, url: str, fetcher: HTTPFetcher) -> Tuple[int, List[str]]:
    """
    –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –æ–¥–∏–Ω –∏—Å—Ç–æ—á–Ω–∏–∫:
    1. –°–∫–∞—á–∏–≤–∞–µ—Ç
    2. –§–∏–ª—å—Ç—Ä—É–µ—Ç –Ω–µ–±–µ–∑–æ–ø–∞—Å–Ω—ã–µ
    3. –§–∏–ª—å—Ç—Ä—É–µ—Ç –ø–æ –ø—Ä–æ—Ç–æ–∫–æ–ª—É
    4. –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø–∏–Ω–≥
    5. –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç 200 –ª—É—á—à–∏—Ö
    """
    log(f"\nüîç –ò—Å—Ç–æ—á–Ω–∏–∫ {idx + 1}: {url[:50]}...")

    # –®–ê–ì 1: –°–∫–∞—á–∏–≤–∞–µ–º
    data = await fetcher.fetch(url)
    if not data:
        log(f"  ‚ùå –ò—Å—Ç–æ—á–Ω–∏–∫ {idx + 1}: –Ω–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å")
        return idx, []

    # –®–ê–ì 2: –§–∏–ª—å—Ç—Ä—É–µ–º –Ω–µ–±–µ–∑–æ–ø–∞—Å–Ω—ã–µ
    data, filtered_insecure = ConfigParser.filter_insecure(data)
    if filtered_insecure > 0:
        log(f"  ‚ÑπÔ∏è –ò—Å—Ç–æ—á–Ω–∏–∫ {idx + 1}: –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–æ {filtered_insecure} –Ω–µ–±–µ–∑–æ–ø–∞—Å–Ω—ã—Ö")

    # –®–ê–ì 3: –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–æ–Ω—Ñ–∏–≥–∏
    all_configs = ConfigParser.extract_keys(data)
    log(f"  üìä –ò—Å—Ç–æ—á–Ω–∏–∫ {idx + 1}: –≤—Å–µ–≥–æ –∫–æ–Ω—Ñ–∏–≥–æ–≤ {len(all_configs)}")

    # –®–ê–ì 4: –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ –ø—Ä–æ—Ç–æ–∫–æ–ª—É
    valid_configs = []
    for c in all_configs:
        proto = c.split('://')[0].lower()
        if proto in ALLOWED_PROTOCOLS:
            valid_configs.append(c)

    log(f"  üî¨ –ò—Å—Ç–æ—á–Ω–∏–∫ {idx + 1}: –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–≤ {len(valid_configs)}")

    if not valid_configs:
        log(f"  ‚ö†Ô∏è –ò—Å—Ç–æ—á–Ω–∏–∫ {idx + 1}: –Ω–µ—Ç –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–≤")
        return idx, []

    # –®–ê–ì 5: –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–∏–Ω–≥ (–Ω–æ –Ω–µ –±–æ–ª—å—à–µ 500, —á—Ç–æ–±—ã –Ω–µ –∑–∞–≤–∏—Å–∞—Ç—å –Ω–∞–¥–æ–ª–≥–æ)
    log(f"  ‚ö° –ò—Å—Ç–æ—á–Ω–∏–∫ {idx + 1}: –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø–∏–Ω–≥–∞...")

    check_limit = min(len(valid_configs), 500)
    sem = asyncio.Semaphore(CONCURRENT_PINGS)
    ping_tasks = []

    for config in valid_configs[:check_limit]:
        ping_tasks.append(check_server_ping(config, sem))

    ping_results = await asyncio.gather(*ping_tasks)

    # –°–æ–±–∏—Ä–∞–µ–º —Ö–æ—Ä–æ—à–∏–µ —Å –ø–∏–Ω–≥–æ–º
    good_servers = []
    for config, ping in ping_results:
        if config:
            good_servers.append((config, ping))

    log(f"  ‚úÖ –ò—Å—Ç–æ—á–Ω–∏–∫ {idx + 1}: —Ö–æ—Ä–æ—à–∏–π –ø–∏–Ω–≥ —É {len(good_servers)} —Å–µ—Ä–≤–µ—Ä–æ–≤")

    if not good_servers:
        return idx, []

    # –®–ê–ì 6: –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –ø–∏–Ω–≥—É –∏ –±–µ—Ä—ë–º –ª—É—á—à–∏–µ SERVERS_PER_SOURCE
    good_servers.sort(key=lambda x: x[1])  # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ –ø–∏–Ω–≥—É
    best_servers = [c for c, _ in good_servers[:SERVERS_PER_SOURCE]]

    log(f"  üèÜ –ò—Å—Ç–æ—á–Ω–∏–∫ {idx + 1}: –≤—ã–±—Ä–∞–Ω–æ {len(best_servers)} –ª—É—á—à–∏—Ö (–ø–∏–Ω–≥ –æ—Ç {good_servers[0][1]:.1f}ms)")

    return idx, best_servers


# -------------------- –°–û–•–†–ê–ù–ï–ù–ò–ï –†–ï–ó–£–õ–¨–¢–ê–¢–û–í --------------------
def save_results(source_results: List[Tuple[int, List[str]]]):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ –ø–∞–ø–∫—É deploy"""
    os.makedirs('deploy/subscriptions', exist_ok=True)

    total_servers = 0
    sources_with_data = 0

    # –°–Ω–∞—á–∞–ª–∞ —É–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–µ —Ñ–∞–π–ª—ã, –µ—Å–ª–∏ –µ—Å—Ç—å
    for idx in range(len(URLS)):
        file_path = f"deploy/subscriptions/{idx + 1}.txt"
        b64_path = f"deploy/subscriptions/{idx + 1}_b64.txt"

        if os.path.exists(file_path):
            os.remove(file_path)
        if os.path.exists(b64_path):
            os.remove(b64_path)

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –Ω–æ–≤—ã–µ
    for idx, servers in source_results:
        if servers:
            file_path = f"deploy/subscriptions/{idx + 1}.txt"
            b64_path = f"deploy/subscriptions/{idx + 1}_b64.txt"

            # –¢–µ–∫—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write('\n'.join(servers))

            # Base64 —Ñ–∞–π–ª
            b64 = base64.b64encode('\n'.join(servers).encode()).decode()
            with open(b64_path, 'w', encoding='utf-8') as f:
                f.write(b64)

            total_servers += len(servers)
            sources_with_data += 1
            log(f"  üíæ –°–æ—Ö—Ä–∞–Ω—ë–Ω {idx + 1}.txt: {len(servers)} —Å–µ—Ä–≤–µ—Ä–æ–≤")

    # –°–æ–∑–¥–∞—ë–º –æ–±—â–∏–π —Ñ–∞–π–ª —Å–æ –≤—Å–µ–º–∏ —Å–µ—Ä–≤–µ—Ä–∞–º–∏
    all_servers = []
    for _, servers in source_results:
        all_servers.extend(servers)

    if all_servers:
        # –¢–µ–∫—Å—Ç–æ–≤—ã–π
        with open('deploy/sub.txt', 'w', encoding='utf-8') as f:
            f.write('\n'.join(all_servers))

        # Base64
        with open('deploy/sub_base64.txt', 'w', encoding='utf-8') as f:
            f.write(base64.b64encode('\n'.join(all_servers).encode()).decode())

    return sources_with_data, total_servers


# -------------------- –û–°–ù–û–í–ù–ê–Ø –§–£–ù–ö–¶–ò–Ø --------------------
async def main():
    start_time = time.time()

    log("=" * 60)
    log("üöÄ –ü–ê–†–°–ï–† VPN –ö–û–ù–§–ò–ì–û–í")
    log("=" * 60)
    log(f"üìä –í—Å–µ–≥–æ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤: {len(URLS)}")
    log(f"‚ö° –ë–µ—Ä—ë–º –ø–æ {SERVERS_PER_SOURCE} –ª—É—á—à–∏—Ö —Å –∫–∞–∂–¥–æ–≥–æ")
    log(f"‚è± –ú–∞–∫—Å. –ø–∏–Ω–≥: {MAX_PING_MS}ms")

    # –®–ê–ì 1: –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≤—Å–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
    log("\nüì• –ó–ê–ì–†–£–ó–ö–ê –ò –û–ë–†–ê–ë–û–¢–ö–ê –ò–°–¢–û–ß–ù–ò–ö–û–í")

    async with HTTPFetcher() as fetcher:
        tasks = []
        for i, url in enumerate(URLS):
            task = process_source(i, url, fetcher)
            tasks.append(task)

        results = await asyncio.gather(*tasks)

    # –®–ê–ì 2: –°–æ—Ä—Ç–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ –Ω–æ–º–µ—Ä—É –∏—Å—Ç–æ—á–Ω–∏–∫–∞
    results.sort(key=lambda x: x[0])

    # –®–ê–ì 3: –°–æ—Ö—Ä–∞–Ω—è–µ–º
    log("\nüíæ –°–û–•–†–ê–ù–ï–ù–ò–ï –†–ï–ó–£–õ–¨–¢–ê–¢–û–í")
    sources_with_data, total_servers = save_results(results)

    # –ò–¢–û–ì
    elapsed = time.time() - start_time

    log("\n" + "=" * 60)
    log("‚úÖ –†–ê–ë–û–¢–ê –ó–ê–í–ï–†–®–ï–ù–ê")
    log("=" * 60)
    log(f"üìä –ò–¢–û–ì–û–í–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
    log(f"   ‚Ä¢ –ò—Å—Ç–æ—á–Ω–∏–∫–æ–≤ —Å –¥–∞–Ω–Ω—ã–º–∏: {sources_with_data}/{len(URLS)}")
    log(f"   ‚Ä¢ –í—Å–µ–≥–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ —Å–µ—Ä–≤–µ—Ä–æ–≤: {total_servers}")
    log(f"   ‚Ä¢ –í —Å—Ä–µ–¥–Ω–µ–º –Ω–∞ –∏—Å—Ç–æ—á–Ω–∏–∫: {total_servers / sources_with_data:.1f} –µ—Å–ª–∏ –µ—Å—Ç—å –¥–∞–Ω–Ω—ã–µ")
    log(f"‚è± –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {elapsed:.1f}—Å")
    log("=" * 60)


log("\nüîç –ü–†–û–í–ï–†–ö–ê –°–û–•–†–ê–ù–Å–ù–ù–´–• –§–ê–ô–õ–û–í:")
if os.path.exists('deploy/subscriptions'):
    files = os.listdir('deploy/subscriptions')
    log(f"   üìÅ –ü–∞–ø–∫–∞ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç, —Ñ–∞–π–ª–æ–≤: {len(files)}")
    for f in sorted(files)[:10]:  # –ü–µ—Ä–≤—ã–µ 10 —Ñ–∞–π–ª–æ–≤
        log(f"      ‚Ä¢ {f}")
else:
    log(f"   ‚ùå –ü–∞–ø–∫–∞ deploy/subscriptions –ù–ï —Å–æ–∑–¥–∞–Ω–∞!")

    # –ü—Ä–æ–≤–µ—Ä–∏–º, —Å–æ–∑–¥–∞–ª–∞—Å—å –ª–∏ –≤–æ–æ–±—â–µ –ø–∞–ø–∫–∞ deploy
    if os.path.exists('deploy'):
        log(f"   üìÅ –ü–∞–ø–∫–∞ deploy —Å—É—â–µ—Å—Ç–≤—É–µ—Ç, –Ω–æ subscriptions - –Ω–µ—Ç")
    else:
        log(f"   ‚ùå –ü–∞–ø–∫–∞ deploy —Ç–æ–∂–µ –Ω–µ —Å–æ–∑–¥–∞–Ω–∞!")

if __name__ == "__main__":
    asyncio.run(main())