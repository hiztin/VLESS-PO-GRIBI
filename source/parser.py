import asyncio
import aiohttp
import re
import base64
import json
import os
import ipaddress
import math
import time
from collections import defaultdict
from urllib.parse import urlparse
from typing import List, Tuple, Optional
from datetime import datetime

# -------------------- –ù–ê–°–¢–†–û–ô–ö–ò --------------------
PING_TIMEOUT = 3.0
MAX_PING_MS = 1000
CONCURRENT_PINGS = 30
SERVERS_PER_SOURCE = 200

ALLOWED_PROTOCOLS = ['vless', 'vmess', 'ss']

# -------------------- –ü–£–¢–ò (–û–¢–ù–û–°–ò–¢–ï–õ–¨–ù–û –ö–û–†–ù–Ø –†–ï–ü–û) --------------------
DEPLOY_PATH = "deploy"
SUBSCRIPTIONS_PATH = f"{DEPLOY_PATH}/subscriptions"

# -------------------- –ò–°–¢–û–ß–ù–ò–ö–ò --------------------
URLS = [
    "https://github.com/sakha1370/OpenRay/raw/refs/heads/main/output/all_valid_proxies.txt",
    "https://raw.githubusercontent.com/sevcator/5ubscrpt10n/main/protocols/vl.txt",
    "https://raw.githubusercontent.com/yitong2333/proxy-minging/refs/heads/main/v2ray.txt",
    "https://raw.githubusercontent.com/acymz/AutoVPN/refs/heads/main/data/V2.txt",
    "https://raw.githubusercontent.com/miladtahanian/V2RayCFGDumper/refs/heads/main/sub.txt",
    "https://raw.githubusercontent.com/roosterkid/openproxylist/main/V2RAY_RAW.txt",
    "https://github.com/Epodonios/v2ray-configs/raw/main/Splitted-By-Protocol/trojan.txt",
    "https://raw.githubusercontent.com/CidVpn/cid-vpn-config/refs/heads/main/general.txt",
    "https://raw.githubusercontent.com/mohamadfg-dev/telegram-v2ray-configs-collector/refs/heads/main/category/vless.txt",
    "https://raw.githubusercontent.com/mheidari98/.proxy/refs/heads/main/vless",
    "https://raw.githubusercontent.com/youfoundamin/V2rayCollector/main/mixed_iran.txt",
    "https://github.com/expressalaki/ExpressVPN/blob/main/configs3.txt",
    "https://raw.githubusercontent.com/MahsaNetConfigTopic/config/refs/heads/main/xray_final.txt",
    "https://github.com/LalatinaHub/Mineral/raw/refs/heads/master/result/nodes",
    "https://github.com/miladtahanian/Config-Collector/raw/refs/heads/main/vless_iran.txt",
    "https://raw.githubusercontent.com/Pawdroid/Free-servers/refs/heads/main/sub",
    "https://github.com/MhdiTaheri/V2rayCollector_Py/raw/refs/heads/main/sub/Mix/mix.txt",
    "https://raw.githubusercontent.com/free18/v2ray/refs/heads/main/v.txt",
    "https://github.com/MhdiTaheri/V2rayCollector/raw/refs/heads/main/sub/mix",
    "https://github.com/Argh94/Proxy-List/raw/refs/heads/main/All_Config.txt",
    "https://raw.githubusercontent.com/shabane/kamaji/master/hub/merged.txt",
    "https://raw.githubusercontent.com/wuqb2i4f/xray-config-toolkit/main/output/base64/mix-uri",
    "https://raw.githubusercontent.com/Delta-Kronecker/V2ray-Config/refs/heads/main/config/protocols/vless.txt",
    "https://raw.githubusercontent.com/STR97/STRUGOV/refs/heads/main/STR.BYPASS#STR.BYPASS%F0%9F%91%BE",
    "https://raw.githubusercontent.com/V2RayRoot/V2RayConfig/refs/heads/main/Config/vless.txt",
]

# -------------------- –õ–û–ì–ò–†–û–í–ê–ù–ò–ï --------------------
def log(message: str):
    """–î–æ–±–∞–≤–ª—è–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ –ª–æ–≥"""
    timestamp = datetime.now().strftime("%H:%M:%S")
    print(f"[{timestamp}] {message}")

# -------------------- HTTP –ö–õ–ò–ï–ù–¢ --------------------
class HTTPFetcher:
    def __init__(self):
        self.headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
        }
        self.session = None
        
    async def __aenter__(self):
        self.session = aiohttp.ClientSession(
            headers=self.headers,
            timeout=aiohttp.ClientTimeout(total=30)
        )
        return self
        
    async def __aexit__(self, *args):
        if self.session:
            await self.session.close()
    
    async def fetch(self, url: str) -> Optional[str]:
        """–ó–∞–≥—Ä—É–∑–∫–∞ —Å retry"""
        for attempt in range(1, 4):
            try:
                async with self.session.get(url, timeout=20, ssl=False) as resp:
                    if resp.status == 200:
                        return await resp.text()
                    else:
                        if attempt < 3:
                            await asyncio.sleep(1)
            except Exception as e:
                if attempt < 3:
                    await asyncio.sleep(1)
        return None

# -------------------- –ü–ê–†–°–ï–† –ö–û–ù–§–ò–ì–û–í --------------------
class ConfigParser:
    INSECURE_PATTERN = re.compile(
        r'(?:[?&;]|3%[Bb])(allowinsecure|allow_insecure|insecure)=(?:1|true|yes)(?:[&;#]|$|(?=\s|$))',
        re.IGNORECASE
    )

    @staticmethod
    def decode_base64(text: str) -> str:
        try:
            text = re.sub(r'\s+', '', text)
            missing = len(text) % 4
            if missing:
                text += '=' * (4 - missing)
            return base64.b64decode(text).decode('utf-8', errors='ignore')
        except:
            return ""

    @staticmethod
    def extract_keys(text: str) -> List[str]:
        if not text:
            return []
        patterns = [
            r'(vmess://[a-zA-Z0-9+/=]+)',
            r'(vless://[a-f0-9-]+@[a-zA-Z0-9.-]+:\d+)',
            r'(ss://[a-zA-Z0-9+/=]+[@#])',
            r'(trojan://[a-zA-Z0-9-]+@[a-zA-Z0-9.-]+:\d+)',
            r'(ss://[a-zA-Z0-9+/=]+)',
        ]
        found = []
        for p in patterns:
            found.extend(re.findall(p, text, re.IGNORECASE))
        return list(set(found))

    @staticmethod
    def extract_host_port(config: str) -> Tuple[Optional[str], Optional[int]]:
        try:
            if config.startswith('vmess://'):
                try:
                    data = config[8:]
                    decoded = ConfigParser.decode_base64(data)
                    if decoded and decoded.startswith('{'):
                        j = json.loads(decoded)
                        return j.get('add'), int(j.get('port', 0))
                except:
                    pass
            
            parsed = urlparse(config)
            if parsed.hostname and parsed.port:
                return parsed.hostname, parsed.port
            
            parts = config.split('://')[1].split('@')
            addr = parts[-1].split('/')[0].split('?')[0]
            if ':' in addr:
                h, p = addr.split(':')
                return h, int(p)
        except:
            pass
        return None, None

    @staticmethod
    def filter_insecure(data: str) -> Tuple[str, int]:
        lines = data.splitlines()
        result = []
        filtered = 0
        
        for line in lines:
            if ConfigParser.INSECURE_PATTERN.search(line):
                filtered += 1
                continue
            result.append(line)
        
        return "\n".join(result), filtered

# -------------------- –ü–†–û–í–ï–†–ö–ê –ü–ò–ù–ì–ê --------------------
async def check_server_ping(config: str, semaphore: asyncio.Semaphore) -> Tuple[Optional[str], Optional[float]]:
    host, port = ConfigParser.extract_host_port(config)
    if not host or not port:
        return None, None
        
    async with semaphore:
        try:
            start = time.time()
            
            try:
                ipaddress.ip_address(host)
            except ValueError:
                await asyncio.get_event_loop().getaddrinfo(host, port)
            
            conn = asyncio.open_connection(host, port)
            _, writer = await asyncio.wait_for(conn, timeout=PING_TIMEOUT)
            
            elapsed = (time.time() - start) * 1000
            writer.close()
            await writer.wait_closed()
            
            if elapsed <= MAX_PING_MS:
                return config, elapsed
            else:
                return None, elapsed
            
        except:
            return None, None

# -------------------- –û–ë–†–ê–ë–û–¢–ö–ê –ò–°–¢–û–ß–ù–ò–ö–ê --------------------
async def process_source(idx: int, url: str, fetcher: HTTPFetcher) -> Tuple[int, List[str]]:
    log(f"\nüîç –ò—Å—Ç–æ—á–Ω–∏–∫ {idx+1}")
    
    data = await fetcher.fetch(url)
    if not data:
        log(f"  ‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å")
        return idx, []
    
    data, filtered_insecure = ConfigParser.filter_insecure(data)
    if filtered_insecure > 0:
        log(f"  ‚ÑπÔ∏è –û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–æ –Ω–µ–±–µ–∑–æ–ø–∞—Å–Ω—ã—Ö: {filtered_insecure}")
    
    all_configs = ConfigParser.extract_keys(data)
    log(f"  üìä –í—Å–µ–≥–æ –∫–æ–Ω—Ñ–∏–≥–æ–≤: {len(all_configs)}")
    
    valid_configs = []
    for c in all_configs:
        proto = c.split('://')[0].lower()
        if proto in ALLOWED_PROTOCOLS:
            valid_configs.append(c)
    
    log(f"  üî¨ –ü–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–≤: {len(valid_configs)}")
    
    if not valid_configs:
        return idx, []
    
    log(f"  ‚ö° –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–∏–Ω–≥–∞...")
    
    check_limit = min(len(valid_configs), 500)
    sem = asyncio.Semaphore(CONCURRENT_PINGS)
    ping_tasks = []
    
    for config in valid_configs[:check_limit]:
        ping_tasks.append(check_server_ping(config, sem))
    
    ping_results = await asyncio.gather(*ping_tasks)
    
    good_servers = []
    for config, ping in ping_results:
        if config:
            good_servers.append((config, ping))
    
    log(f"  ‚úÖ –•–æ—Ä–æ—à–∏–π –ø–∏–Ω–≥ —É {len(good_servers)}")
    
    if not good_servers:
        return idx, []
    
    good_servers.sort(key=lambda x: x[1])
    best_servers = [c for c, _ in good_servers[:SERVERS_PER_SOURCE]]
    
    if best_servers:
        log(f"  üèÜ –û—Ç–æ–±—Ä–∞–Ω–æ {len(best_servers)} –ª—É—á—à–∏—Ö")
    
    return idx, best_servers

# -------------------- –°–û–•–†–ê–ù–ï–ù–ò–ï –ù–ê –ì–ò–¢–•–ê–ë --------------------
def save_results(source_results: List[Tuple[int, List[str]]]):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ñ–∞–π–ª—ã –ø—Ä—è–º–æ –≤ –ø–∞–ø–∫—É —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è"""
    
    # –°–û–ó–î–ê–Å–ú –ü–ê–ü–ö–ò –ü–†–Ø–ú–û –ó–î–ï–°–¨
    os.makedirs(SUBSCRIPTIONS_PATH, exist_ok=True)
    
    log(f"\nüíæ –°–û–•–†–ê–ù–ï–ù–ò–ï –í {DEPLOY_PATH}")
    log(f"   –ü–∞–ø–∫–∞ —Å–æ–∑–¥–∞–Ω–∞: {os.path.exists(DEPLOY_PATH)}")
    log(f"   –ü–æ–¥–ø–∞–ø–∫–∞ —Å–æ–∑–¥–∞–Ω–∞: {os.path.exists(SUBSCRIPTIONS_PATH)}")
    
    total_servers = 0
    sources_with_data = 0
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ –æ–¥–Ω–æ–º—É —Ñ–∞–π–ª—É –Ω–∞ –∏—Å—Ç–æ—á–Ω–∏–∫
    for idx, servers in source_results:
        if servers:
            # –¢–µ–∫—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª
            txt_path = os.path.join(SUBSCRIPTIONS_PATH, f"{idx+1}.txt")
            with open(txt_path, 'w', encoding='utf-8') as f:
                f.write('\n'.join(servers))
            
            # Base64 —Ñ–∞–π–ª
            b64_path = os.path.join(SUBSCRIPTIONS_PATH, f"{idx+1}_b64.txt")
            b64 = base64.b64encode('\n'.join(servers).encode()).decode()
            with open(b64_path, 'w', encoding='utf-8') as f:
                f.write(b64)
            
            log(f"  ‚úÖ {idx+1}.txt: {len(servers)} —Å–µ—Ä–≤–µ—Ä–æ–≤")
            total_servers += len(servers)
            sources_with_data += 1
    
    # –û–±—â–∏–π —Ñ–∞–π–ª
    all_servers = []
    for _, servers in source_results:
        all_servers.extend(servers)
    
    if all_servers:
        txt_path = os.path.join(DEPLOY_PATH, "sub.txt")
        with open(txt_path, 'w', encoding='utf-8') as f:
            f.write('\n'.join(all_servers))
        
        b64_path = os.path.join(DEPLOY_PATH, "sub_base64.txt")
        b64 = base64.b64encode('\n'.join(all_servers).encode()).decode()
        with open(b64_path, 'w', encoding='utf-8') as f:
            f.write(b64)
        
        log(f"  ‚úÖ sub.txt: {len(all_servers)} –≤—Å–µ–≥–æ —Å–µ—Ä–≤–µ—Ä–æ–≤")
    
    # –ü–†–û–í–ï–†–Ø–ï–ú, –ß–¢–û –§–ê–ô–õ–´ –†–ï–ê–õ–¨–ù–û –°–û–ó–î–ê–õ–ò–°–¨
    log("\nüîç –ü–†–û–í–ï–†–ö–ê:")
    if os.path.exists(DEPLOY_PATH):
        files = os.listdir(DEPLOY_PATH)
        log(f"   –í {DEPLOY_PATH} –Ω–∞–π–¥–µ–Ω–æ: {files}")
    else:
        log(f"   ‚ùå {DEPLOY_PATH} –ù–ï –°–£–©–ï–°–¢–í–£–ï–¢!")
    
    if os.path.exists(SUBSCRIPTIONS_PATH):
        files = os.listdir(SUBSCRIPTIONS_PATH)
        log(f"   –í {SUBSCRIPTIONS_PATH} –Ω–∞–π–¥–µ–Ω–æ: {sorted(files)[:5]}")
    else:
        log(f"   ‚ùå {SUBSCRIPTIONS_PATH} –ù–ï –°–£–©–ï–°–¢–í–£–ï–¢!")
    
    return sources_with_data, total_servers

# -------------------- –û–°–ù–û–í–ù–ê–Ø –§–£–ù–ö–¶–ò–Ø --------------------
async def main():
    start_time = time.time()
    
    print("\n" + "="*60)
    print("üöÄ –ü–ê–†–°–ï–† –î–õ–Ø –ì–ò–¢–•–ê–ë–ê")
    print("="*60)
    print(f"üìÅ –ë—É–¥–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤: {DEPLOY_PATH}")
    
    # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ —Å–æ–∑–¥–∞—ë–º –ø–∞–ø–∫–∏ –µ—â—ë —Ä–∞–∑
    os.makedirs(DEPLOY_PATH, exist_ok=True)
    os.makedirs(SUBSCRIPTIONS_PATH, exist_ok=True)
    
    async with HTTPFetcher() as fetcher:
        tasks = [process_source(i, url, fetcher) for i, url in enumerate(URLS)]
        results = await asyncio.gather(*tasks)
    
    results.sort(key=lambda x: x[0])
    sources_with_data, total_servers = save_results(results)
    
    elapsed = time.time() - start_time
    print("\n" + "="*60)
    print("‚úÖ –†–ê–ë–û–¢–ê –ó–ê–í–ï–†–®–ï–ù–ê")
    print("="*60)
    print(f"üìä –ò—Å—Ç–æ—á–Ω–∏–∫–æ–≤ —Å –¥–∞–Ω–Ω—ã–º–∏: {sources_with_data}/{len(URLS)}")
    print(f"üìä –í—Å–µ–≥–æ —Å–µ—Ä–≤–µ—Ä–æ–≤: {total_servers}")
    print(f"‚è± –í—Ä–µ–º—è: {elapsed:.1f}—Å")
    print("="*60)

if __name__ == "__main__":
    asyncio.run(main())
