import asyncio
import aiohttp
import re
import base64
import json
import os
import ipaddress
import math
import time
from collections import defaultdict
from urllib.parse import urlparse
from typing import List, Tuple, Optional
from datetime import datetime
import zoneinfo


PING_TIMEOUT = 3.0
MAX_PING_MS = 1000
CONCURRENT_PINGS = 30
SERVERS_PER_SOURCE = 200

ALLOWED_PROTOCOLS = ['vless', 'vmess', 'ss']

# –ü–£–¢–ò (–û–¢–ù–û–°–ò–¢–ï–õ–¨–ù–û –ö–û–†–ù–Ø –†–ï–ü–û)
DEPLOY_PATH = "deploy"
SUBSCRIPTIONS_PATH = f"{DEPLOY_PATH}/subscriptions"


URLS = [
    "https://github.com/sakha1370/OpenRay/raw/refs/heads/main/output/all_valid_proxies.txt",
    "https://raw.githubusercontent.com/sevcator/5ubscrpt10n/main/protocols/vl.txt",
    "https://raw.githubusercontent.com/yitong2333/proxy-minging/refs/heads/main/v2ray.txt",
    "https://raw.githubusercontent.com/acymz/AutoVPN/refs/heads/main/data/V2.txt",
    "https://raw.githubusercontent.com/miladtahanian/V2RayCFGDumper/refs/heads/main/sub.txt",
    "https://raw.githubusercontent.com/roosterkid/openproxylist/main/V2RAY_RAW.txt",
    "https://github.com/Epodonios/v2ray-configs/raw/main/Splitted-By-Protocol/trojan.txt",
    "https://raw.githubusercontent.com/CidVpn/cid-vpn-config/refs/heads/main/general.txt",
    "https://raw.githubusercontent.com/mohamadfg-dev/telegram-v2ray-configs-collector/refs/heads/main/category/vless.txt",
    "https://raw.githubusercontent.com/mheidari98/.proxy/refs/heads/main/vless",
    "https://raw.githubusercontent.com/youfoundamin/V2rayCollector/main/mixed_iran.txt",
    "https://github.com/expressalaki/ExpressVPN/blob/main/configs3.txt",
    "https://raw.githubusercontent.com/MahsaNetConfigTopic/config/refs/heads/main/xray_final.txt",
    "https://github.com/LalatinaHub/Mineral/raw/refs/heads/master/result/nodes",
    "https://github.com/miladtahanian/Config-Collector/raw/refs/heads/main/vless_iran.txt",
    "https://raw.githubusercontent.com/Pawdroid/Free-servers/refs/heads/main/sub",
    "https://github.com/MhdiTaheri/V2rayCollector_Py/raw/refs/heads/main/sub/Mix/mix.txt",
    "https://raw.githubusercontent.com/free18/v2ray/refs/heads/main/v.txt",
    "https://github.com/MhdiTaheri/V2rayCollector/raw/refs/heads/main/sub/mix",
    "https://github.com/Argh94/Proxy-List/raw/refs/heads/main/All_Config.txt",
    "https://raw.githubusercontent.com/shabane/kamaji/master/hub/merged.txt",
    "https://raw.githubusercontent.com/wuqb2i4f/xray-config-toolkit/main/output/base64/mix-uri",
    "https://raw.githubusercontent.com/Delta-Kronecker/V2ray-Config/refs/heads/main/config/protocols/vless.txt",
    "https://raw.githubusercontent.com/STR97/STRUGOV/refs/heads/main/STR.BYPASS#STR.BYPASS%F0%9F%91%BE",
    "https://raw.githubusercontent.com/V2RayRoot/V2RayConfig/refs/heads/main/Config/vless.txt",
]

# –õ–û–ì–ò–†–û–í–ê–ù–ò–ï
def log(message: str):
    """–î–æ–±–∞–≤–ª—è–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ –ª–æ–≥"""
    timestamp = datetime.now().strftime("%H:%M:%S")
    print(f"[{timestamp}] {message}")

#  HTTP –ö–õ–ò–ï–ù–¢ 
class HTTPFetcher:
    def __init__(self):
        self.headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
        }
        self.session = None

    async def __aenter__(self):
        self.session = aiohttp.ClientSession(
            headers=self.headers,
            timeout=aiohttp.ClientTimeout(total=30)
        )
        return self

    async def __aexit__(self, *args):
        if self.session:
            await self.session.close()

    async def fetch(self, url: str) -> Optional[str]:
        """–ó–∞–≥—Ä—É–∑–∫–∞ —Å retry"""
        for attempt in range(1, 4):
            try:
                async with self.session.get(url, timeout=20, ssl=False) as resp:
                    if resp.status == 200:
                        return await resp.text()
                    else:
                        if attempt < 3:
                            await asyncio.sleep(1)
            except Exception as e:
                if attempt < 3:
                    await asyncio.sleep(1)
        return None

#–ü–ê–†–°–ï–† –ö–û–ù–§–ò–ì–û–í
class ConfigParser:
    INSECURE_PATTERN = re.compile(
        r'(?:[?&;]|3%[Bb])(allowinsecure|allow_insecure|insecure)=(?:1|true|yes)(?:[&;#]|$|(?=\s|$))',
        re.IGNORECASE
    )

    @staticmethod
    def decode_base64(text: str) -> str:
        try:
            text = re.sub(r'\s+', '', text)
            missing = len(text) % 4
            if missing:
                text += '=' * (4 - missing)
            return base64.b64decode(text).decode('utf-8', errors='ignore')
        except:
            return ""

    @staticmethod
    def extract_keys(text: str) -> List[str]:
        if not text:
            return []
        patterns = [
            r'(vmess://[a-zA-Z0-9+/=]+)',
            r'(vless://[a-f0-9-]+@[a-zA-Z0-9.-]+:\d+)',
            r'(ss://[a-zA-Z0-9+/=]+[@#])',
            r'(trojan://[a-zA-Z0-9-]+@[a-zA-Z0-9.-]+:\d+)',
            r'(ss://[a-zA-Z0-9+/=]+)',
        ]
        found = []
        for p in patterns:
            found.extend(re.findall(p, text, re.IGNORECASE))
        return list(set(found))

    @staticmethod
    def extract_host_port(config: str) -> Tuple[Optional[str], Optional[int]]:
        try:
            if config.startswith('vmess://'):
                try:
                    data = config[8:]
                    decoded = ConfigParser.decode_base64(data)
                    if decoded and decoded.startswith('{'):
                        j = json.loads(decoded)
                        return j.get('add'), int(j.get('port', 0))
                except:
                    pass

            parsed = urlparse(config)
            if parsed.hostname and parsed.port:
                return parsed.hostname, parsed.port

            parts = config.split('://')[1].split('@')
            addr = parts[-1].split('/')[0].split('?')[0]
            if ':' in addr:
                h, p = addr.split(':')
                return h, int(p)
        except:
            pass
        return None, None

    @staticmethod
    def filter_insecure(data: str) -> Tuple[str, int]:
        lines = data.splitlines()
        result = []
        filtered = 0

        for line in lines:
            if ConfigParser.INSECURE_PATTERN.search(line):
                filtered += 1
                continue
            result.append(line)

        return "\n".join(result), filtered

# –ü–†–û–í–ï–†–ö–ê –ü–ò–ù–ì–ê
async def check_server_ping(config: str, semaphore: asyncio.Semaphore) -> Tuple[Optional[str], Optional[float]]:
    host, port = ConfigParser.extract_host_port(config)
    if not host or not port:
        return None, None

    async with semaphore:
        try:
            start = time.time()

            try:
                ipaddress.ip_address(host)
            except ValueError:
                await asyncio.get_event_loop().getaddrinfo(host, port)

            conn = asyncio.open_connection(host, port)
            _, writer = await asyncio.wait_for(conn, timeout=PING_TIMEOUT)

            elapsed = (time.time() - start) * 1000
            writer.close()
            await writer.wait_closed()

            if elapsed <= MAX_PING_MS:
                return config, elapsed
            else:
                return None, elapsed

        except:
            return None, None

#–û–ë–†–ê–ë–û–¢–ö–ê –ò–°–¢–û–ß–ù–ò–ö–ê
async def process_source(idx: int, url: str, fetcher: HTTPFetcher) -> Tuple[int, List[str]]:
    log(f"\nüîç –ò—Å—Ç–æ—á–Ω–∏–∫ {idx + 1}")

    data = await fetcher.fetch(url)
    if not data:
        log(f"  ‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å")
        return idx, []

    data, filtered_insecure = ConfigParser.filter_insecure(data)
    if filtered_insecure > 0:
        log(f"  ‚ÑπÔ∏è –û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–æ –Ω–µ–±–µ–∑–æ–ø–∞—Å–Ω—ã—Ö: {filtered_insecure}")

    all_configs = ConfigParser.extract_keys(data)
    log(f"  üìä –í—Å–µ–≥–æ –∫–æ–Ω—Ñ–∏–≥–æ–≤: {len(all_configs)}")

    valid_configs = []
    for c in all_configs:
        proto = c.split('://')[0].lower()
        if proto in ALLOWED_PROTOCOLS:
            valid_configs.append(c)

    log(f"  üî¨ –ü–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–≤: {len(valid_configs)}")

    if not valid_configs:
        return idx, []

    log(f"  ‚ö° –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–∏–Ω–≥–∞...")

    check_limit = min(len(valid_configs), 500)
    sem = asyncio.Semaphore(CONCURRENT_PINGS)
    ping_tasks = []

    for config in valid_configs[:check_limit]:
        ping_tasks.append(check_server_ping(config, sem))

    ping_results = await asyncio.gather(*ping_tasks)

    good_servers = []
    for config, ping in ping_results:
        if config:
            good_servers.append((config, ping))

    log(f"  ‚úÖ –•–æ—Ä–æ—à–∏–π –ø–∏–Ω–≥ —É {len(good_servers)}")

    if not good_servers:
        return idx, []

    good_servers.sort(key=lambda x: x[1])
    best_servers = [c for c, _ in good_servers[:SERVERS_PER_SOURCE]]

    if best_servers:
        log(f"  üèÜ –û—Ç–æ–±—Ä–∞–Ω–æ {len(best_servers)} –ª—É—á—à–∏—Ö")

    return idx, best_servers

# –°–û–•–†–ê–ù–ï–ù–ò–ï –í –§–ê–ô–õ–´ (–¢–û–õ–¨–ö–û .TXT)
def save_results(source_results: List[Tuple[int, List[str]]]):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ç–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ —Ñ–∞–π–ª—ã .txt"""
    os.makedirs(SUBSCRIPTIONS_PATH, exist_ok=True)

    log(f"\nüíæ –°–û–•–†–ê–ù–ï–ù–ò–ï –í {DEPLOY_PATH}")

    total_servers = 0
    sources_with_data = 0

    for idx, servers in source_results:
        if servers:
            txt_path = os.path.join(SUBSCRIPTIONS_PATH, f"{idx + 1}.txt")
            with open(txt_path, 'w', encoding='utf-8') as f:
                f.write('\n'.join(servers))

            log(f"  ‚úÖ {idx + 1}.txt: {len(servers)} —Å–µ—Ä–≤–µ—Ä–æ–≤")
            total_servers += len(servers)
            sources_with_data += 1

    # –û–±—â–∏–π —Ñ–∞–π–ª
    all_servers = []
    for _, servers in source_results:
        all_servers.extend(servers)

    if all_servers:
        txt_path = os.path.join(DEPLOY_PATH, "sub.txt")
        with open(txt_path, 'w', encoding='utf-8') as f:
            f.write('\n'.join(all_servers))

        log(f"  ‚úÖ sub.txt: {len(all_servers)} –≤—Å–µ–≥–æ —Å–µ—Ä–≤–µ—Ä–æ–≤")

    return sources_with_data, total_servers
def force_commit_update():
    """
    –ñ—ë—Å—Ç–∫–æ —Å–æ–∑–¥–∞—ë—Ç –∏–∑–º–µ–Ω–µ–Ω–∏—è –¥–ª—è –∫–æ–º–º–∏—Ç–∞:
    1. –û–±–Ω–æ–≤–ª—è–µ—Ç –¥–∞—Ç—É –≤ README
    2. –°–æ–∑–¥–∞—ë—Ç —Ñ–∞–π–ª —Å timestamp
    """
    from datetime import datetime
    import zoneinfo
    import os
    
    # –¢–µ–∫—É—â–µ–µ –≤—Ä–µ–º—è
    zone = zoneinfo.ZoneInfo("Europe/Moscow")
    now = datetime.now(zone)
    time_str = now.strftime("%H:%M")
    date_str = now.strftime("%d.%m.%Y")
    
    # 1. –û–±–Ω–æ–≤–ª—è–µ–º timestamp –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º —Ñ–∞–π–ª–µ
    with open("deploy/last_update.txt", "w", encoding="utf-8") as f:
        f.write(f"–ü–æ—Å–ª–µ–¥–Ω–µ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ: {date_str} {time_str}")
    
    # 2. –û–±–Ω–æ–≤–ª—è–µ–º README.md –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ
    readme_path = "README.md"
    if os.path.exists(readme_path):
        with open(readme_path, "r", encoding="utf-8") as f:
            content = f.read()
        
        # –ò—â–µ–º –∏ –æ–±–Ω–æ–≤–ª—è–µ–º –¥–∞—Ç—É
        import re
        new_content = re.sub(
            r'(–ü–æ—Å–ª–µ–¥–Ω–µ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ:|–æ–±–Ω–æ–≤–ª–µ–Ω–æ:|–û–±–Ω–æ–≤–ª–µ–Ω–æ:).*',
            f'\\1 {date_str} {time_str}',
            content,
            flags=re.IGNORECASE
        )
        
        # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ - –¥–æ–±–∞–≤–ª—è–µ–º –≤ –∫–æ–Ω–µ—Ü
        if new_content == content:
            new_content += f"\n\n*–ü–æ—Å–ª–µ–¥–Ω–µ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ: {date_str} {time_str}*\n"
        
        with open(readme_path, "w", encoding="utf-8") as f:
            f.write(new_content)
    
    print(f"‚úÖ –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ: {date_str} {time_str}")
    return True
# –ì–ï–ù–ï–†–ê–¶–ò–Ø README 
def generate_readme():
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç README.md —Å —Ç–∞–±–ª–∏—Ü–µ–π —Å—Ç–∞—Ç—É—Å–æ–≤ –∏ —Ç–æ–ª—å–∫–æ .txt —Å—Å—ã–ª–∫–∞–º–∏"""
    
    # –¢–µ–∫—É—â–µ–µ –≤—Ä–µ–º—è –ø–æ –ú–æ—Å–∫–≤–µ
    zone = zoneinfo.ZoneInfo("Europe/Moscow")
    current_time = datetime.now(zone)
    time_str = current_time.strftime("%H:%M")
    date_str = current_time.strftime("%d.%m.%Y")
    
    # –°–ø–∏—Å–æ–∫ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ —Å –Ω–∞–∑–≤–∞–Ω–∏—è–º–∏
    source_names = [
        "sakha1370/OpenRay",
        "sevcator/5ubscrpt10n",
        "yitong2333/proxy-minging",
        "acymz/AutoVPN",
        "miladtahanian/V2RayCFGDumper",
        "roosterkid/openproxylist",
        "Epodonios/v2ray-configs",
        "CidVpn/cid-vpn-config",
        "mohamadfg-dev/telegram-v2ray-configs-collector",
        "mheidari98/.proxy",
        "youfoundamin/V2rayCollector",
        "expressalaki/ExpressVPN",
        "MahsaNetConfigTopic/config",
        "LalatinaHub/Mineral",
        "miladtahanian/Config-Collector",
        "Pawdroid/Free-servers",
        "MhdiTaheri/V2rayCollector_Py",
        "free18/v2ray",
        "MhdiTaheri/V2rayCollector",
        "Argh94/Proxy-List",
        "shabane/kamaji",
        "wuqb2i4f/xray-config-toolkit",
        "Delta-Kronecker/V2ray-Config",
        "STR97/STRUGOV",
        "V2RayRoot/V2RayConfig",
    ]
    
    subs_dir = "deploy/subscriptions"
    existing_files = set()
    if os.path.exists(subs_dir):
        for f in os.listdir(subs_dir):
            match = re.match(r'(\d+)\.txt', f)
            if match:
                existing_files.add(int(match.group(1)))
    
    status_table = ""
    for i, source in enumerate(source_names, 1):
        filename = f"{i}.txt"
        if i in existing_files:
            status_table += f"| {i} | `{filename}` | {source} | {time_str} | {date_str} |\n"
        else:
            status_table += f"| {i} | `{filename}` | {source} | ‚è≥ –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö | ‚è≥ –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö |\n"
    
    # –¢–∞–±–ª–∏—Ü–∞ —Ä–∞–±–æ—á–∏—Ö —Å—Å—ã–ª–æ–∫ (—Ç–æ–ª—å–∫–æ .txt)
    working_table = ""
    BASE_RAW_URL = "https://raw.githubusercontent.com/hiztin/VLESS-PO-GRIBI/main/deploy/subscriptions"
    
    for i in range(1, 26):
        if os.path.exists(f"deploy/subscriptions/{i}.txt"):
            working_table += f"| {i} | [`{i}.txt`]({BASE_RAW_URL}/{i}.txt) |\n"
    
    # –ü–æ–¥—Å—á—ë—Ç —Å–µ—Ä–≤–µ—Ä–æ–≤
    total_servers = 0
    if os.path.exists("deploy/sub.txt"):
        with open("deploy/sub.txt", "r", encoding="utf-8") as f:
            total_servers = len(f.readlines())
    
    readme_content = f"""# üçÑ VLESS –ü–û –ì–†–ò–ë–´ - –ë–µ—Å–ø–ª–∞—Ç–Ω—ã–µ VPN –ø–æ–¥–ø–∏—Å–∫–∏ 

<div align="center">
  
### üçÑ‚Äçüü´ –ï–∂–µ–¥–Ω–µ–≤–Ω–æ –æ–±–Ω–æ–≤–ª—è–µ–º–∞—è –∫–æ–ª–ª–µ–∫—Ü–∏—è —Ä–∞–±–æ—á–∏—Ö VPN-—Å–µ—Ä–≤–µ—Ä–æ–≤

[![GitHub last commit](https://img.shields.io/github/last-commit/hiztin/VLESS-PO-GRIBI)](https://github.com/hiztin/VLESS-PO-GRIBI/commits/main)
[![GitHub Workflow Status](https://img.shields.io/github/actions/workflow/status/hiztin/VLESS-PO-GRIBI/update-subscriptions.yml)](https://github.com/hiztin/VLESS-PO-GRIBI/actions)
[![License](https://img.shields.io/github/license/hiztin/VLESS-PO-GRIBI)](LICENSE)
![–°–µ—Ä–≤–µ—Ä–æ–≤](https://img.shields.io/badge/dynamic/json?url=https://raw.githubusercontent.com/hiztin/VLESS-PO-GRIBI/main/deploy/debug.json&query=alive&label=—Ä–∞–±–æ—á–∏—Ö&color=green)

</div>

## üçÑ‚Äçüü´ –û –ø—Ä–æ–µ–∫—Ç–µ

–≠—Ç–æ—Ç –ø—Ä–æ–µ–∫—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–æ–±–∏—Ä–∞–µ—Ç –∏ –ø—Ä–æ–≤–µ—Ä—è–µ—Ç **–±–µ—Å–ø–ª–∞—Ç–Ω—ã–µ VPN-—Å–µ—Ä–≤–µ—Ä—ã** –∏–∑ –æ—Ç–∫—Ä—ã—Ç—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤. –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç **–∫–∞–∂–¥—ã–π –¥–µ–Ω—å** —á–µ—Ä–µ–∑ GitHub Actions, –ø–æ—ç—Ç–æ–º—É –ø–æ–¥–ø–∏—Å–∫–∏ –≤—Å–µ–≥–¥–∞ –∞–∫—Ç—É–∞–ª—å–Ω—ã. –ü—Ä–æ–µ–∫—Ç –µ—â—ë –≤ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ,
–ø–æ—ç—Ç–æ–º—É –ø–æ–¥–ø–∏—Å–∫–∏ –Ω–µ –ø–æ–¥–ø–∏—Å–∞–Ω—ã –∏\–∏–ª–∏ —á—Ç–æ-—Ç–æ –º–æ–∂–µ—Ç –Ω–µ —Ä–∞–±–æ—Ç–∞—Ç—å

---

## üìä –°—Ç–∞—Ç—É—Å –∫–æ–Ω—Ñ–∏–≥–æ–≤

> ‚ö†Ô∏è **–í–Ω–∏–º–∞–Ω–∏–µ!** –≠—Ç–∞ —Ç–∞–±–ª–∏—Ü–∞ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Ç–æ–ª—å–∫–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –∏ —Å—Ç–∞—Ç—É—Å –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –∫–æ–Ω—Ñ–∏–≥–æ–≤. **–ù–µ –∫–æ–ø–∏—Ä—É–π—Ç–µ —Å—Å—ã–ª–∫–∏ –æ—Ç—Å—é–¥–∞!**  
> –î–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –∫–æ–ø–∏—Ä—É–π—Ç–µ —Å—Å—ã–ª–∫–∏ –∏–∑ —Ä–∞–∑–¥–µ–ª–∞ **¬´üçÑ –†–∞–±–æ—á–∏–µ –∫–æ–Ω—Ñ–∏–≥–∏¬ª** –Ω–∏–∂–µ.

| ‚Ññ | –§–∞–π–ª | –ò—Å—Ç–æ—á–Ω–∏–∫ | –í—Ä–µ–º—è | –î–∞—Ç–∞ |
|---|------|----------|-------|------|
{status_table}

---

## üçÑ –†–∞–±–æ—á–∏–µ –∫–æ–Ω—Ñ–∏–≥–∏

### üì¶ –ü–æ–ª–Ω–∞—è –ø–æ–¥–ø–∏—Å–∫–∞ (–≤—Å–µ —Å–µ—Ä–≤–µ—Ä—ã —Å—Ä–∞–∑—É)

`https://raw.githubusercontent.com/hiztin/VLESS-PO-GRIBI/main/deploy/sub.txt`

### üìÅ –ö–æ–Ω—Ñ–∏–≥–∏ –ø–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º (–ø–æ 200 –ª—É—á—à–∏—Ö —Å –∫–∞–∂–¥–æ–≥–æ)

| ‚Ññ | –°—Å—ã–ª–∫–∞ –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è |
|---|----------------------|
{working_table}

**[üçÑ –û—Ç–∫—Ä—ã—Ç—å –ø–∞–ø–∫—É —Å–æ –≤—Å–µ–º–∏ —Ñ–∞–π–ª–∞–º–∏](https://github.com/hiztin/VLESS-PO-GRIBI/tree/main/deploy/subscriptions)**

---

## üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞

- **–í—Å–µ–≥–æ —Å–µ—Ä–≤–µ—Ä–æ–≤**: ~{total_servers}+
- **–ê–∫—Ç–∏–≤–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤**: {len(existing_files)}
- **–ü—Ä–æ—Ç–æ–∫–æ–ª—ã**: VMess, VLESS, Shadowsocks (Trojan –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω)
- **–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ**: –∫–∞–∂–¥—ã–µ 3 —á–∞—Å–∞ UTC
- **–ü–æ—Å–ª–µ–¥–Ω–µ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ**: {time_str} {date_str}

---

## üçÑ –ö–æ–Ω—Ç–∞–∫—Ç—ã –∏ –ø–æ–¥–¥–µ—Ä–∂–∫–∞

- **Discord**: `h1zz`
- **GitHub Issues**: [–°–æ–∑–¥–∞—Ç—å issue](https://github.com/hiztin/VLESS-PO-GRIBI/issues)

---

<div align="center">

### ‚≠ê –ï—Å–ª–∏ –ø—Ä–æ–µ–∫—Ç –ø–æ–ª–µ–∑–µ–Ω, –ø–æ—Å—Ç–∞–≤—å –∑–≤–µ–∑–¥—É! ‚≠ê

[![GitHub stars](https://img.shields.io/github/stars/hiztin/VLESS-PO-GRIBI?style=social)](https://github.com/hiztin/VLESS-PO-GRIBI/stargazers)

</div>
"""
    
    with open("README.md", "w", encoding="utf-8") as f:
        f.write(readme_content)
    
    print(f"‚úÖ README.md –æ–±–Ω–æ–≤–ª—ë–Ω! ({len(existing_files)} –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤, {total_servers} —Å–µ—Ä–≤–µ—Ä–æ–≤)")

# –û–°–ù–û–í–ù–ê–Ø –§–£–ù–ö–¶–ò–Ø
async def main():
    start_time = time.time()

    print("\n" + "=" * 60)
    print("üöÄ –ü–ê–†–°–ï–† –î–õ–Ø –ì–ò–¢–•–ê–ë–ê")
    print("=" * 60)
    print(f"üìÅ –ë—É–¥–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤: {DEPLOY_PATH}")

    os.makedirs(DEPLOY_PATH, exist_ok=True)
    os.makedirs(SUBSCRIPTIONS_PATH, exist_ok=True)

    async with HTTPFetcher() as fetcher:
        tasks = [process_source(i, url, fetcher) for i, url in enumerate(URLS)]
        results = await asyncio.gather(*tasks)

    results.sort(key=lambda x: x[0])
    sources_with_data, total_servers = save_results(results)
    
    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º README –ø–æ—Å–ª–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
    generate_readme()

    elapsed = time.time() - start_time
    print("\n" + "=" * 60)
    print("‚úÖ –†–ê–ë–û–¢–ê –ó–ê–í–ï–†–®–ï–ù–ê")
    print("=" * 60)
    print(f"üìä –ò—Å—Ç–æ—á–Ω–∏–∫–æ–≤ —Å –¥–∞–Ω–Ω—ã–º–∏: {sources_with_data}/{len(URLS)}")
    print(f"üìä –í—Å–µ–≥–æ —Å–µ—Ä–≤–µ—Ä–æ–≤: {total_servers}")
    print(f"‚è± –í—Ä–µ–º—è: {elapsed:.1f}—Å")
    print("=" * 60)
force_commit_update()

if __name__ == "__main__":
    asyncio.run(main())



