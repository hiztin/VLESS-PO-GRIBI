import asyncio
import httpx
import re
import base64
import json
import os
import ipaddress
import math
import time
import statistics
from urllib.parse import urlparse
from typing import List, Tuple, Optional

SOURCES = [
    "https://raw.githubusercontent.com/barry-far/V2ray-Config/refs/heads/main/All_Configs_Sub.txt",
    # "https://raw.githubusercontent.com/Epodonios/v2ray-configs/refs/heads/main/All_Configs_Sub.txt",
    #"https://raw.githubusercontent.com/ebrasha/free-v2ray-public-list/refs/heads/main/all_extracted_configs.txt"
]
TIMEOUT = 7.0
CONCURRENT_LIMIT = 50
SERVERS_PER_FILE = 200

MAX_PING_MS = 800
MIN_PING_MS = 10
PING_SAMPLES = 2

# –ü—Ä–æ—Ç–æ–∫–æ–ª—ã, –∫–æ—Ç–æ—Ä—ã–µ –Ω—É–∂–Ω–æ —Å–æ—Ö—Ä–∞–Ω—è—Ç—å
ALLOWED_PROTOCOLS = ['vless', 'vmess', 'ss']


class TurboParser:
    def __init__(self):
        self.headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
        }
        self.servers_with_ping: List[Tuple[str, float]] = []

    def decode_base64(self, text):
        """–ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ Base64"""
        try:
            text = re.sub(r'\s+', '', text)
            missing_padding = len(text) % 4
            if missing_padding:
                text += '=' * (4 - missing_padding)
            decoded = base64.b64decode(text).decode('utf-8', errors='ignore')
            return decoded
        except Exception:
            return ""

    def extract_keys(self, text):
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–ª—é—á–µ–π –∏–∑ —Ç–µ–∫—Å—Ç–∞"""
        if not text:
            return []

        patterns = [
            r'(vmess://[a-zA-Z0-9+/=]+)',
            r'(vless://[a-f0-9-]+@[a-zA-Z0-9.-]+:\d+)',
            r'(ss://[a-zA-Z0-9+/=]+[@#])',
            r'(trojan://[a-zA-Z0-9-]+@[a-zA-Z0-9.-]+:\d+)',
            r'(ss://[a-zA-Z0-9+/=]+)',
        ]

        found = []
        for pattern in patterns:
            found.extend(re.findall(pattern, text, re.IGNORECASE))

        return list(set(found))

    def filter_by_protocol(self, configs):
        """–û—Å—Ç–∞–≤–ª—è–µ—Ç —Ç–æ–ª—å–∫–æ —Å–µ—Ä–≤–µ—Ä—ã —Å —Ä–∞–∑—Ä–µ—à—ë–Ω–Ω—ã–º–∏ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞–º–∏"""
        filtered = []
        removed = []

        for config in configs:
            protocol = config.split('://')[0].lower()
            if protocol in ALLOWED_PROTOCOLS:
                filtered.append(config)
            else:
                removed.append(config)

        print(f"üîç –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–≤:")
        print(f"   ‚úÖ –û—Å—Ç–∞–≤–ª–µ–Ω–æ ({len(filtered)}): {', '.join(ALLOWED_PROTOCOLS)}")
        print(f"   ‚ùå –£–¥–∞–ª–µ–Ω–æ ({len(removed)}): trojan –∏ –¥—Ä—É–≥–∏–µ")
        return filtered

    def extract_host_port(self, config):
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ö–æ—Å—Ç–∞ –∏ –ø–æ—Ä—Ç–∞ –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞"""
        try:
            if config.startswith('vmess://'):
                try:
                    vmess_data = config[8:]
                    decoded = self.decode_base64(vmess_data)
                    if decoded:
                        data = json.loads(decoded)
                        return data.get('add'), int(data.get('port', 0))
                except:
                    pass

            parsed = urlparse(config)
            if parsed.hostname and parsed.port:
                return parsed.hostname, parsed.port

            parts = config.split('://')[1].split('@')
            if len(parts) > 1:
                addr_part = parts[-1]
            else:
                addr_part = parts[0]

            addr_part = addr_part.split('/')[0].split('?')[0]
            if ':' in addr_part:
                host, port_str = addr_part.split(':')
                return host, int(port_str)

        except Exception:
            pass
        return None, None

    async def fetch_source(self, client, url):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∏–∑ –∏—Å—Ç–æ—á–Ω–∏–∫–∞"""
        try:
            print(f"[*] –ó–∞–ø—Ä–æ—Å –∫: {url}")
            r = await client.get(url, timeout=20.0, follow_redirects=True)
            print(f"    [!] –°—Ç–∞—Ç—É—Å: {r.status_code}, –†–∞–∑–º–µ—Ä: {len(r.text)} –±–∞–π—Ç")

            if r.status_code != 200:
                return []

            raw_data = r.text
            found = []
            found.extend(self.extract_keys(raw_data))

            for line in raw_data.split('\n'):
                line = line.strip()
                if line and len(line) > 20:
                    decoded = self.decode_base64(line)
                    if decoded and '://' in decoded:
                        found.extend(self.extract_keys(decoded))

            if found:
                print(f"    [+] –ù–∞–π–¥–µ–Ω–æ —Å—Å—ã–ª–æ–∫: {len(set(found))}")
            return list(set(found))
        except Exception as e:
            print(f"    [X] –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ {url}: {e}")
            return []

    async def check_server_with_ping(self, config, semaphore):
        """–£–º–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞ —Å –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ –∑–∞–º–µ—Ä–∞–º–∏"""
        host, port = self.extract_host_port(config)

        if not host or not port:
            return None, None

        async with semaphore:
            try:
                # –î–µ–ª–∞–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ –∑–∞–º–µ—Ä–æ–≤
                pings = []

                for sample in range(PING_SAMPLES):
                    try:
                        start = time.time()

                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º DNS –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
                        try:
                            ipaddress.ip_address(host)
                        except ValueError:
                            await asyncio.get_event_loop().getaddrinfo(host, port)

                        # –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è
                        conn = asyncio.open_connection(host, port)
                        _, writer = await asyncio.wait_for(conn, timeout=TIMEOUT)

                        elapsed = (time.time() - start) * 1000
                        pings.append(elapsed)

                        writer.close()
                        await writer.wait_closed()

                        # –ù–µ–±–æ–ª—å—à–∞—è –ø–∞—É–∑–∞ –º–µ–∂–¥—É –∑–∞–º–µ—Ä–∞–º–∏
                        if sample < PING_SAMPLES - 1:
                            await asyncio.sleep(0.1)

                    except Exception:
                        return None, None

                # –ë–µ—Ä—ë–º –º–µ–¥–∏–∞–Ω—É (—É—Å—Ç–æ–π—á–∏–≤–∞ –∫ –≤—ã–±—Ä–æ—Å–∞–º)
                final_ping = statistics.median(pings)

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω–æ—Å—Ç—å
                if final_ping < MIN_PING_MS or final_ping > 2000:
                    return None, None

                print(f"    [LIVE] {host}:{port} - {final_ping:.1f}ms (–º–µ–¥–∏–∞–Ω–∞ –∏–∑ {PING_SAMPLES})")
                return config, final_ping

            except asyncio.TimeoutError:
                return None, None
            except Exception:
                return None, None


def split_into_files(data, base_filename="sub", items_per_file=SERVERS_PER_FILE):
    """–†–∞–∑–±–∏–≤–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Å–µ—Ä–≤–µ—Ä–æ–≤ –Ω–∞ –º–∞–ª–µ–Ω—å–∫–∏–µ —Ñ–∞–π–ª—ã"""
    if not data:
        print("‚ö†Ô∏è –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ä–∞–∑–±–∏–≤–∫–∏")
        return []

    subs_dir = os.path.join('deploy', 'subscriptions')
    os.makedirs(subs_dir, exist_ok=True)

    total_items = len(data)
    num_files = math.ceil(total_items / items_per_file)

    print(f"\n--- –†–ê–ó–ë–ò–í–ö–ê –ù–ê {num_files} –ú–ê–õ–ï–ù–¨–ö–ò–• –§–ê–ô–õ–û–í ---")

    created_files = []

    for i in range(num_files):
        start_idx = i * items_per_file
        end_idx = min((i + 1) * items_per_file, total_items)

        chunk = data[start_idx:end_idx]
        chunk_text = "\n".join(chunk)

        file_number = i + 1
        file_prefix = f"{base_filename}_{file_number:03d}"

        txt_filename = f"{file_prefix}.txt"
        txt_path = os.path.join(subs_dir, txt_filename)
        with open(txt_path, 'w', encoding='utf-8') as f:
            f.write(chunk_text)
        created_files.append(txt_path)

        b64_filename = f"{file_prefix}_b64.txt"
        b64_path = os.path.join(subs_dir, b64_filename)
        chunk_b64 = base64.b64encode(chunk_text.encode()).decode()
        with open(b64_path, 'w', encoding='utf-8') as f:
            f.write(chunk_b64)
        created_files.append(b64_path)

        print(f"  [{file_number:03d}/{num_files:03d}] {txt_filename}: {len(chunk)} —Å–µ—Ä–≤–µ—Ä–æ–≤")

    create_links_file(subs_dir, num_files, base_filename)
    print(f"‚úÖ –í—Å–µ–≥–æ —Å–æ–∑–¥–∞–Ω–æ —Ñ–∞–π–ª–æ–≤: {len(created_files)}")
    return created_files


def create_links_file(subs_dir, num_files, base_filename):
    """–°–æ–∑–¥–∞—ë—Ç —Ñ–∞–π–ª —Å–æ –≤—Å–µ–º–∏ —Å—Å—ã–ª–∫–∞–º–∏"""
    links_path = os.path.join(subs_dir, 'all_links.txt')
    base_url = "https://raw.githubusercontent.com/hiztin/VLESS-PO-GRIBI/main/deploy/subscriptions"

    with open(links_path, 'w', encoding='utf-8') as f:
        f.write("# –í—Å–µ —Å—Å—ã–ª–∫–∏ –Ω–∞ –º–∞–ª–µ–Ω—å–∫–∏–µ –ø–æ–¥–ø–∏—Å–∫–∏ (VLESS/VMess/SS)\n\n")
        f.write("## Base64 —Å—Å—ã–ª–∫–∏ (–¥–ª—è V2Ray/V2Box)\n")
        for i in range(num_files):
            file_num = i + 1
            f.write(f"{base_url}/sub_{file_num:03d}_b64.txt\n")

        f.write("\n## –¢–µ–∫—Å—Ç–æ–≤—ã–µ —Å—Å—ã–ª–∫–∏ (–¥–ª—è —Ä—É—á–Ω–æ–≥–æ –∏–º–ø–æ—Ä—Ç–∞)\n")
        for i in range(num_files):
            file_num = i + 1
            f.write(f"{base_url}/sub_{file_num:03d}.txt\n")

    print(f"üîó –°–æ–∑–¥–∞–Ω —Ñ–∞–π–ª —Å–æ —Å—Å—ã–ª–∫–∞–º–∏: {links_path}")


def save_sorted_by_ping(servers_with_ping: List[Tuple[str, float]]):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Å–µ—Ä–≤–µ—Ä—ã, –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–æ –ø–∏–Ω–≥—É"""
    if not servers_with_ping:
        return

    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –ø–∏–Ω–≥—É
    sorted_servers = sorted(servers_with_ping, key=lambda x: x[1])
    sorted_configs = [s[0] for s in sorted_servers]

    os.makedirs('deploy', exist_ok=True)

    # –¢–µ–∫—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª
    with open('deploy/sub_sorted.txt', 'w', encoding='utf-8') as f:
        f.write("\n".join(sorted_configs))

    # Base64 —Ñ–∞–π–ª
    with open('deploy/sub_sorted_b64.txt', 'w', encoding='utf-8') as f:
        all_b64 = base64.b64encode("\n".join(sorted_configs).encode()).decode()
        f.write(all_b64)

    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –ø–∏–Ω–≥—É
    ping_values = [p for _, p in sorted_servers]

    # –ö–≤–∞—Ä—Ç–∏–ª–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
    q1 = statistics.quantiles(ping_values, n=4)[0] if len(ping_values) >= 4 else 0
    q3 = statistics.quantiles(ping_values, n=4)[2] if len(ping_values) >= 4 else 0

    ping_details = []
    for config, ping_ms in sorted_servers[:50]:  # –¢–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ 50 –¥–ª—è —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏
        host, _ = extract_host_port_simple(config)
        ping_details.append({
            'host': host,
            'ping_ms': round(ping_ms, 1),
            'quality': '–±—ã—Å—Ç—Ä—ã–π' if ping_ms < 200 else '—Å—Ä–µ–¥–Ω–∏–π' if ping_ms < 400 else '–º–µ–¥–ª–µ–Ω–Ω—ã–π'
        })

    with open('deploy/ping_stats.json', 'w', encoding='utf-8') as f:
        json.dump({
            'total': len(sorted_servers),
            'min_ping': round(min(ping_values), 1),
            'max_ping': round(max(ping_values), 1),
            'avg_ping': round(statistics.mean(ping_values), 1),
            'median_ping': round(statistics.median(ping_values), 1),
            'q1_ping': round(q1, 1),
            'q3_ping': round(q3, 1),
            'fast_servers': len([p for p in ping_values if p < 200]),
            'medium_servers': len([p for p in ping_values if 200 <= p < 400]),
            'slow_servers': len([p for p in ping_values if p >= 400]),
            'samples_per_server': PING_SAMPLES,
            'servers_by_ping': ping_details
        }, f, indent=2, ensure_ascii=False)

    print(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –ø–∏–Ω–≥—É:")
    print(f"   ‚Ä¢ –ú–∏–Ω: {min(ping_values):.1f}ms, –ú–∞–∫—Å: {max(ping_values):.1f}ms")
    print(f"   ‚Ä¢ –°—Ä–µ–¥–Ω–∏–π: {statistics.mean(ping_values):.1f}ms")
    print(f"   ‚Ä¢ –ú–µ–¥–∏–∞–Ω–∞: {statistics.median(ping_values):.1f}ms")
    print(f"   ‚Ä¢ –ë—ã—Å—Ç—Ä—ã—Ö (<200ms): {len([p for p in ping_values if p < 200])}")
    print(f"   ‚Ä¢ –ú–µ–¥–ª–µ–Ω–Ω—ã—Ö (>400ms): {len([p for p in ping_values if p >= 400])}")

    return sorted_configs


def extract_host_port_simple(config):
    """–£–ø—Ä–æ—â—ë–Ω–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ö–æ—Å—Ç–∞ –¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏"""
    try:
        if config.startswith('vmess://'):
            return "vmess-server", 0
        parsed = urlparse(config)
        if parsed.hostname:
            return parsed.hostname, parsed.port or 0
        return "unknown", 0
    except:
        return "unknown", 0


def filter_by_ping_intelligently(servers_with_ping: List[Tuple[str, float]]):
    """
    –£–º–Ω–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ –ø–∏–Ω–≥—É:
    - –ù–µ –æ—Ç—Å–µ–∫–∞–µ–º –≤—Å–µ—Ö –ø–æ–¥—Ä—è–¥, –∞ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ
    """
    if not servers_with_ping:
        return []

    ping_values = [p for _, p in servers_with_ping]

    # –ï—Å–ª–∏ —Å–µ—Ä–≤–µ—Ä–æ–≤ –º–∞–ª–æ - –æ—Å—Ç–∞–≤–ª—è–µ–º –≤—Å–µ
    if len(ping_values) < 10:
        print(f"‚ö†Ô∏è –ú–∞–ª–æ —Å–µ—Ä–≤–µ—Ä–æ–≤ ({len(ping_values)}), –æ—Å—Ç–∞–≤–ª—è–µ–º –≤—Å–µ")
        return servers_with_ping

    median_ping = statistics.median(ping_values)
    q3 = statistics.quantiles(ping_values, n=4)[2] if len(ping_values) >= 4 else median_ping * 1.5

    threshold = min(median_ping * 2, q3 * 1.2, 800)  

    filtered = [(c, p) for c, p in servers_with_ping if p <= threshold]
    removed = len(servers_with_ping) - len(filtered)

    print(f"üìä –ê–Ω–∞–ª–∏–∑ –ø–∏–Ω–≥–∞:")
    print(f"   ‚Ä¢ –ú–µ–¥–∏–∞–Ω–∞: {median_ping:.1f}ms")
    print(f"   ‚Ä¢ –ü–æ—Ä–æ–≥ –æ—Ç—Å–µ—á–µ–Ω–∏—è: {threshold:.1f}ms")
    print(f"   ‚Ä¢ –û—Å—Ç–∞–≤–ª–µ–Ω–æ: {len(filtered)}, –æ—Ç—Å–µ—è–Ω–æ: {removed}")

    return filtered


def save_main_files(alive_servers, total_found):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –æ—Å–Ω–æ–≤–Ω—ã–µ —Ñ–∞–π–ª—ã"""
    os.makedirs('deploy', exist_ok=True)

    with open('deploy/sub.txt', 'w', encoding='utf-8') as f:
        f.write("\n".join(alive_servers))

    with open('deploy/sub_base64.txt', 'w', encoding='utf-8') as f:
        all_b64 = base64.b64encode("\n".join(alive_servers).encode()).decode()
        f.write(all_b64)

    with open('deploy/debug.json', 'w', encoding='utf-8') as f:
        protocols = {}
        for server in alive_servers[:100]:
            proto = server.split('://')[0]
            protocols[proto] = protocols.get(proto, 0) + 1

        json.dump({
            'total': total_found,
            'alive': len(alive_servers),
            'allowed_protocols': ALLOWED_PROTOCOLS,
            'date': str(__import__('datetime').datetime.now()),
            'protocol_stats': protocols,
            'servers_preview': alive_servers[:10]
        }, f, indent=2, ensure_ascii=False)

    print(f"üì¶ –û—Å–Ω–æ–≤–Ω—ã–µ —Ñ–∞–π–ª—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ deploy/")


def save_protocol_stats(servers):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞–º"""
    stats = {}
    for server in servers:
        protocol = server.split('://')[0]
        stats[protocol] = stats.get(protocol, 0) + 1

    stats_path = os.path.join('deploy', 'protocol_stats.json')
    with open(stats_path, 'w', encoding='utf-8') as f:
        json.dump({
            'total': len(servers),
            'by_protocol': stats,
            'filtered_out': ['trojan']
        }, f, indent=2)

    print(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞–º: {stats}")


async def main():
    start_time = time.time()
    parser = TurboParser()

    transport = httpx.AsyncHTTPTransport(retries=2)

    async with httpx.AsyncClient(
            transport=transport,
            verify=False,
            follow_redirects=True,
            headers=parser.headers,
            timeout=30.0
    ) as client:

        print("üîç –°–ë–û–† –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–ô")
        tasks = [parser.fetch_source(client, url) for url in SOURCES]
        results = await asyncio.gather(*tasks, return_exceptions=True)

        raw_links = []
        for result in results:
            if isinstance(result, list):
                raw_links.extend(result)

        unique_links = list(set(raw_links))
        print(f"\nüìä –í–°–ï–ì–û –£–ù–ò–ö–ê–õ–¨–ù–´–•: {len(unique_links)}")

        if not unique_links:
            print("‚ùå –°—Å—ã–ª–æ–∫ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ. –°–æ–∑–¥–∞—é —Ç–µ—Å—Ç–æ–≤—ã–µ —Ñ–∞–π–ª—ã")
            test_servers = [
                "vmess://eyJhZGQiOiJ0ZXN0LmNvbSIsInBvcnQiOiI4MCIsImlkIjoiMTIzNDU2Nzg5MCJ9",
                "vless://test-uuid@test.com:443?security=tls",
                "ss://YWVzLTI1Ni1nY206dGVzdEB0ZXN0LmNvbTo4MA=="
            ]
            save_main_files(test_servers, 3)
            split_into_files(test_servers, items_per_file=2)
            return

        print("\n‚ö° –ü–†–û–í–ï–†–ö–ê –î–û–°–¢–£–ü–ù–û–°–¢–ò –ò –ó–ê–ú–ï–† –ü–ò–ù–ì–ê")
        sem = asyncio.Semaphore(CONCURRENT_LIMIT)

        check_tasks = [parser.check_server_with_ping(link, sem) for link in unique_links]
        results_with_ping = await asyncio.gather(*check_tasks)

        servers_with_ping = [(c, p) for c, p in results_with_ping if c is not None]

        print(f"\nüìä –î–û–°–¢–£–ü–ù–û –°–ï–†–í–ï–†–û–í: {len(servers_with_ping)}")

        if not servers_with_ping:
            print("‚ùå –ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —Å–µ—Ä–≤–µ—Ä–æ–≤")
            return
        servers_with_ping = filter_by_ping_intelligently(servers_with_ping)

        alive_configs = [c for c, _ in servers_with_ping]

        print(f"\nüî¨ –§–ò–õ–¨–¢–†–ê–¶–ò–Ø –ü–û –ü–†–û–¢–û–ö–û–õ–ê–ú")
        filtered_servers = parser.filter_by_protocol(alive_configs)

        filtered_with_ping = [(c, p) for c, p in servers_with_ping if c in filtered_servers]

        print(f"\nüíæ –°–û–•–†–ê–ù–ï–ù–ò–ï –†–ï–ó–£–õ–¨–¢–ê–¢–û–í ({len(filtered_with_ping)} —Å–µ—Ä–≤–µ—Ä–æ–≤)")

        if filtered_with_ping:
            save_main_files([c for c, _ in filtered_with_ping], len(unique_links))
            save_protocol_stats([c for c, _ in filtered_with_ping])
            sorted_configs = save_sorted_by_ping(filtered_with_ping)

            # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ —Ñ–∞–π–ª—ã
            split_into_files(sorted_configs, items_per_file=SERVERS_PER_FILE)

            elapsed = time.time() - start_time
            print("\n" + "=" * 60)
            print("‚úÖ –í–°–Å –£–°–ü–ï–®–ù–û –ó–ê–í–ï–†–®–ï–ù–û!")
            print("=" * 60)
            print(f"üìä –í—Å–µ–≥–æ —Å–µ—Ä–≤–µ—Ä–æ–≤: {len(filtered_with_ping)}")
            print(f"‚ö° –ú–µ–¥–∏–∞–Ω–Ω—ã–π –ø–∏–Ω–≥: {statistics.median([p for _, p in filtered_with_ping]):.1f}ms")
            print(f"‚è± –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {elapsed:.1f}—Å")
        else:
            print("‚ùå –ù–µ—Ç —Å–µ—Ä–≤–µ—Ä–æ–≤ –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏")


if __name__ == "__main__":
    asyncio.run(main())
